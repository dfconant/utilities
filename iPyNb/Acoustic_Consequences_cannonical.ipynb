{
 "metadata": {
  "name": "",
  "signature": "sha256:ea0b36c56ca7b935fec25b5576550b72a03cb9a432998049f956013ef35482b8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "from ECoGstats import makeD_multi, smooth_formants, LARS_MLR,Ds2Xy,Ridge_MLR,process_kin, normalize_contour_length, shuffle_df,subtract_baseline,SemiPartialCorrelation\n",
      "import seaborn as sns\n",
      "import prettyplotlib as ppl\n",
      "from matplotlib.backends.backend_agg import (FigureCanvasAgg as FigureCanvas)\n",
      "from scipy.signal import savgol_filter\n",
      "import pandas as pd\n",
      "from BDutils import ProgressBar, resample_array, smart_toeplitz, smooth_derivative,seq_labels,procrustes_mean\n",
      "from ecog_viz import gestural_score,R2viz, plotkhat, set_style_black\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.lda import LDA\n",
      "from sklearn.linear_model import Lars\n",
      "import scipy as sp\n",
      "import itertools\n",
      "\n",
      "import scipy.stats as stats\n",
      "import matplotlib.gridspec as gridspec\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import VisEcog\n",
      "import imaging\n",
      "import os\n",
      "import matplotlib.image as mpimg\n",
      "import brewer2mpl\n",
      "import re\n",
      "set_style_black()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The autoreload extension is already loaded. To reload it, use:\n",
        "  %reload_ext autoreload\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pth = '/Users/david_conant/Dropbox/Vowels/EC41/'\n",
      "blocks = [19,20,22,27]\n",
      "tokens = ['AAA','IYY','UWW','AEE','AHH','EHH','ERR','IHH','UHH']\n",
      "#tokens = ['HAWED','HEED','WHOOD','HAD','HUD','HEAD','HEARD','HID','HOOD']\n",
      "kfeats = ['kFrontTongueX','kFMidTongueX','kMidTongueX','kBMidTongueX','kBackTongueX','kFrontTongueY','kFMidTongueY','kMidTongueY',\n",
      "          'kBMidTongueY','kBackTongueY','kLipOpening','kLipWidth','kJawX','kJawY']\n",
      "efeats = seq_labels('e',256)\n",
      "fs = 100\n",
      "#Load in Dmatrices\n",
      "\n",
      "#Electrodes\n",
      "window = np.array([-1,2])   #TODO: try wider window for more timepoints\n",
      "[E,anat,stop_times,start_times] = makeD_multi(pth,blocks,tokens,align_window = window, dtype='HG')\n",
      "Es = [E[d] for d in tokens]\n",
      "vSMC = np.concatenate((np.where(anat=='preCG')[0],np.where(anat=='postCG')[0]))\n",
      "vSMC_logic = np.zeros(256,dtype=bool)\n",
      "vSMC_logic[vSMC] = True\n",
      "Eall = np.concatenate(Es,axis=2)\n",
      "#Eall = subtract_baseline(Eall)\n",
      "#Eall = resample_array(Eall,[Eall.shape[0],np.diff(window)[0]*fs,Eall.shape[2]])\n",
      "\n",
      "#Kinematics\n",
      "#window = np.array([0.25,0.75])\n",
      "[K,anat,stop_times,start_times] = makeD_multi(pth,blocks,tokens,dtype='kin',align_window = window)\n",
      "Ks = [K[d] for d in tokens]\n",
      "stops = [stop_times[d] for d in tokens]\n",
      "starts = [start_times[d] for d in tokens]\n",
      "#Ks,meanTng,Z,d = procrustes_tongue(Ks[:],scale=True,viz=False)\n",
      "Ks = process_kin(Ks,stops,starts,window,numTongue=6,wrt_start=True,norm_length=False)\n",
      "Kall = np.concatenate(Ks,axis=2)\n",
      "#Kall = resample_array(Kall,[Kall.shape[0],np.diff(window)[0]*fs,Kall.shape[2]])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "File found; Loading...\n",
        "Loaded"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "File found; Loading..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loaded"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "CV = 'split'\n",
      "boot = 50\n",
      "ncomp = 40\n",
      "nTP = 200\n",
      "alphas = np.logspace(-2,8,20)\n",
      "#alphas = range(20)\n",
      "\n",
      "window = np.array([-1, 2])\n",
      "[E,anat,stop_times,start_times] = makeD_multi(pth,blocks,tokens,align_window = window, dtype='HG')\n",
      "Es = [E[d] for d in tokens]\n",
      "#elects = np.concatenate((np.where(anat=='preCG')[0],np.where(anat=='postCG')[0]))\n",
      "elects = [21,25,35,37,43,53,55,58,59,67,72,73,86,90,102]\n",
      "\n",
      "Kr2 = np.empty((Ks[0].shape[0],boot,nTP,len(alphas)))\n",
      "Kr2null = np.empty((Ks[0].shape[0],boot,nTP,len(alphas)))\n",
      "\n",
      "prog = ProgressBar(nTP)\n",
      "for indt,t in enumerate(np.linspace(200,600,nTP)):\n",
      "    erange = np.arange(t,t+4)   #Try playing with window size\n",
      "\n",
      "    #Organize data into X and y\n",
      "    X,y,yrnd = Ds2Xy(Es,Ks,dt1='HG',dt2='kin',ncomp = ncomp,erange = erange.astype(int),elects = elects,frange=np.arange(105,115),krange=np.arange(37,42))\n",
      "    #y= Korig[:,:,0,0]\n",
      "    #Ridge regression\n",
      "    for inda,a in enumerate(alphas):\n",
      "        Kr2[:,:,indt,inda],coefs,yhat,score = Ridge_MLR(X, y, alpha = a, CV = CV, boot = boot)\n",
      "        Kr2null[:,:,indt,inda],coefs,yhat,score = Ridge_MLR(X, yrnd, alpha = a, CV = CV, boot = boot)\n",
      "    prog.animate(indt)\n",
      "R2viz(Kr2,Kr2null,kfeats,b=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "File found; Loading...\n",
        "Loaded"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [                       0%                       ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " [                       1%                       ]  1 of 200 complete"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "notes = []\n",
      "for ind,n in enumerate(tokens):\n",
      "    notes.append([n]*Ks[ind].shape[2])\n",
      "notes = np.concatenate(notes,axis=0) \n",
      "plotkhat(Korig,Khat,kfeats,notes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "(174, 10)"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Ks[0].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "(10, 90, 21)"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}