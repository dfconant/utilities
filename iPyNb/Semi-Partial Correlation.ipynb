{
 "metadata": {
  "name": "",
  "signature": "sha256:29146d6a826c8459dd5a99c682de1c12a2a2f724c0e0fc67e9061717ef534d06"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "from ECoGstats import makeD_multi, smooth_formants, process_kin, SemiPartialCorrelation, Ds2Xy\n",
      "import seaborn as sns\n",
      "import prettyplotlib as ppl\n",
      "from matplotlib.backends.backend_agg import (FigureCanvasAgg as FigureCanvas)\n",
      "from scipy.signal import savgol_filter\n",
      "import pandas as pd\n",
      "from BDutils import ProgressBar, resample_array, smart_toeplitz, smooth_derivative\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.lda import LDA\n",
      "from sklearn.linear_model import Ridge\n",
      "import scipy as sp\n",
      "\n",
      "import scipy.stats as stats\n",
      "import matplotlib.gridspec as gridspec\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import statsmodels.formula.api as sm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The autoreload extension is already loaded. To reload it, use:\n",
        "  %reload_ext autoreload\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subj = 'EC41'\n",
      "blocks = [19,20,22,27]\n",
      "pth = '/Users/david_conant/Dropbox/Vowels/'+subj + '/'\n",
      "tokens = ['AAA','IYY','UWW','AEE','AHH','EHH','ERR','IHH','UHH']\n",
      "window = np.array([-1,2])\n",
      "[K,anat,stop_times,start_times] = makeD_multi(pth,blocks,tokens,dtype= 'kin',align_window = window)\n",
      "Ks = [K[d].copy() for d in tokens]\n",
      "notes = []\n",
      "for ind,n in enumerate(tokens):\n",
      "    notes.append([n]*Ks[ind].shape[2])\n",
      "notes = np.concatenate(notes,axis=0) \n",
      "\n",
      "stops = [stop_times[d] for d in tokens]\n",
      "starts = [start_times[d] for d in tokens]\n",
      "Ks = process_kin(Ks,stops,starts,window, norm_length=True,velocity = False,wrt_start=True)\n",
      "Kall = np.concatenate(Ks,axis=2)\n",
      "kfeats = ['FrontTongueX','MidTongueX', 'BackTongueX','FrontTongueY','MidTongueY',\n",
      "         'BackTongueY','LipOpening','LipWidth','JawX','JawY']\n",
      "sns.set_palette('Set1')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "File found; Loading...\n",
        "Loaded"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "CV = 'split'\n",
      "boot = 50\n",
      "ncomp = 40\n",
      "nTP = 200\n",
      "alphas = np.logspace(-2,15,20)\n",
      "Kt = Ks\n",
      "\n",
      "window = np.array([-1, 2])\n",
      "[E,anat,stop_times,start_times] = makeD_multi(pth,blocks,tokens,align_window = window, dtype='HG')\n",
      "Es = [E[d] for d in tokens]\n",
      "elects = np.concatenate((np.where(anat=='preCG')[0],np.where(anat=='postCG')[0]))\n",
      "\n",
      "Kr2 = np.empty((Ks[0].shape[0],boot,nTP,len(alphas)))\n",
      "Kr2null = np.empty((Ks[0].shape[0],boot,nTP,len(alphas)))\n",
      "B = np.empty((Ks[0].shape[0],elects.shape[0]-1,boot,nTP,len(alphas)))\n",
      "\n",
      "prog = ProgressBar(nTP)\n",
      "t = 400\n",
      "erange = np.arange(t,t+4)   #Try playing with window size\n",
      "\n",
      "#Organize data into X and y\n",
      "X,y,yrnd = Ds2Xy(Es,Kt,dt1='HG',dt2='kin',ncomp = ncomp,erange = erange.astype(int),elects = elects,frange=np.arange(105,115),krange=np.arange(37,42))\n",
      "\n",
      "X = pd.DataFrame(X)\n",
      "y = pd.DataFrame(y,columns = kfeats)\n",
      "#Semi-partial Correlation \n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "File found; Loading...\n",
        "Loaded"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "yhat,ytilde = SemiPartialCorrelation(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ytilde"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>FrontTongueX</th>\n",
        "      <th>MidTongueX</th>\n",
        "      <th>BackTongueX</th>\n",
        "      <th>FrontTongueY</th>\n",
        "      <th>MidTongueY</th>\n",
        "      <th>BackTongueY</th>\n",
        "      <th>LipOpening</th>\n",
        "      <th>LipWidth</th>\n",
        "      <th>JawX</th>\n",
        "      <th>JawY</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>-0.016784</td>\n",
        "      <td>0.113194</td>\n",
        "      <td>-0.045649</td>\n",
        "      <td>-0.131102</td>\n",
        "      <td>0.051586</td>\n",
        "      <td>0.144505</td>\n",
        "      <td>-0.411826</td>\n",
        "      <td>-0.615102</td>\n",
        "      <td>-0.370511</td>\n",
        "      <td>0.890536</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>0.385174</td>\n",
        "      <td>-0.188575</td>\n",
        "      <td>0.052170</td>\n",
        "      <td>-0.350112</td>\n",
        "      <td>0.311132</td>\n",
        "      <td>-0.838375</td>\n",
        "      <td>-0.264705</td>\n",
        "      <td>-0.868285</td>\n",
        "      <td>-0.156445</td>\n",
        "      <td>0.738678</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>0.058937</td>\n",
        "      <td>0.058705</td>\n",
        "      <td>-0.170865</td>\n",
        "      <td>-0.183885</td>\n",
        "      <td>0.009933</td>\n",
        "      <td>-0.472895</td>\n",
        "      <td>-0.107436</td>\n",
        "      <td>-0.164013</td>\n",
        "      <td>0.093702</td>\n",
        "      <td>0.279770</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>-0.347491</td>\n",
        "      <td>0.346719</td>\n",
        "      <td>-0.405352</td>\n",
        "      <td>-0.185396</td>\n",
        "      <td>-0.154935</td>\n",
        "      <td>0.235288</td>\n",
        "      <td>-0.115504</td>\n",
        "      <td>-0.137162</td>\n",
        "      <td>0.179457</td>\n",
        "      <td>0.305118</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>0.077035</td>\n",
        "      <td>-0.055551</td>\n",
        "      <td>0.022085</td>\n",
        "      <td>0.167029</td>\n",
        "      <td>-0.156917</td>\n",
        "      <td>0.316097</td>\n",
        "      <td>1.477717</td>\n",
        "      <td>-0.820016</td>\n",
        "      <td>-1.248787</td>\n",
        "      <td>-0.370890</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td>0.022378</td>\n",
        "      <td>0.092889</td>\n",
        "      <td>-0.306242</td>\n",
        "      <td>0.084112</td>\n",
        "      <td>-0.081311</td>\n",
        "      <td>0.227204</td>\n",
        "      <td>0.629907</td>\n",
        "      <td>-0.405928</td>\n",
        "      <td>-0.238213</td>\n",
        "      <td>-0.366594</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td>0.023430</td>\n",
        "      <td>-0.050927</td>\n",
        "      <td>0.080615</td>\n",
        "      <td>0.121351</td>\n",
        "      <td>-0.102925</td>\n",
        "      <td>0.133585</td>\n",
        "      <td>0.495302</td>\n",
        "      <td>-0.147596</td>\n",
        "      <td>-0.207296</td>\n",
        "      <td>-0.409146</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td>-0.068856</td>\n",
        "      <td>0.026652</td>\n",
        "      <td>0.004040</td>\n",
        "      <td>0.149435</td>\n",
        "      <td>-0.178467</td>\n",
        "      <td>0.805722</td>\n",
        "      <td>-0.092662</td>\n",
        "      <td>-0.735853</td>\n",
        "      <td>0.697806</td>\n",
        "      <td>0.007550</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td>0.011662</td>\n",
        "      <td>0.080171</td>\n",
        "      <td>-0.169174</td>\n",
        "      <td>-0.426397</td>\n",
        "      <td>0.025873</td>\n",
        "      <td>-0.621662</td>\n",
        "      <td>0.381227</td>\n",
        "      <td>0.804530</td>\n",
        "      <td>-0.504299</td>\n",
        "      <td>0.126464</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td>-0.152007</td>\n",
        "      <td>0.035285</td>\n",
        "      <td>0.243506</td>\n",
        "      <td>0.179251</td>\n",
        "      <td>-0.426397</td>\n",
        "      <td>1.271683</td>\n",
        "      <td>0.216889</td>\n",
        "      <td>-0.350256</td>\n",
        "      <td>-0.111978</td>\n",
        "      <td>-0.075231</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td>0.039370</td>\n",
        "      <td>-0.020255</td>\n",
        "      <td>0.038111</td>\n",
        "      <td>-0.209975</td>\n",
        "      <td>0.081847</td>\n",
        "      <td>-0.296705</td>\n",
        "      <td>-0.026040</td>\n",
        "      <td>-0.280818</td>\n",
        "      <td>0.416691</td>\n",
        "      <td>0.081428</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td>-0.201339</td>\n",
        "      <td>0.156803</td>\n",
        "      <td>-0.147352</td>\n",
        "      <td>-0.173866</td>\n",
        "      <td>-0.089751</td>\n",
        "      <td>-0.402035</td>\n",
        "      <td>-0.296207</td>\n",
        "      <td>0.174523</td>\n",
        "      <td>-0.494182</td>\n",
        "      <td>0.086640</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td>0.066960</td>\n",
        "      <td>0.161490</td>\n",
        "      <td>-0.455558</td>\n",
        "      <td>-0.110680</td>\n",
        "      <td>-0.052426</td>\n",
        "      <td>-0.160828</td>\n",
        "      <td>1.701323</td>\n",
        "      <td>-0.168305</td>\n",
        "      <td>-1.699293</td>\n",
        "      <td>-0.421316</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td>-0.000439</td>\n",
        "      <td>-0.074349</td>\n",
        "      <td>0.306744</td>\n",
        "      <td>0.023557</td>\n",
        "      <td>-0.177582</td>\n",
        "      <td>0.643209</td>\n",
        "      <td>0.513103</td>\n",
        "      <td>1.084878</td>\n",
        "      <td>0.363536</td>\n",
        "      <td>-1.002593</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td>-0.061850</td>\n",
        "      <td>-0.020844</td>\n",
        "      <td>0.282932</td>\n",
        "      <td>-0.303326</td>\n",
        "      <td>0.182130</td>\n",
        "      <td>-0.414353</td>\n",
        "      <td>-0.146584</td>\n",
        "      <td>-0.297878</td>\n",
        "      <td>0.242532</td>\n",
        "      <td>0.106996</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td>-0.162194</td>\n",
        "      <td>0.158350</td>\n",
        "      <td>-0.163957</td>\n",
        "      <td>-0.041736</td>\n",
        "      <td>-0.113606</td>\n",
        "      <td>0.243233</td>\n",
        "      <td>-0.293383</td>\n",
        "      <td>-0.117034</td>\n",
        "      <td>0.237710</td>\n",
        "      <td>-0.017171</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td>0.042390</td>\n",
        "      <td>-0.094684</td>\n",
        "      <td>0.187372</td>\n",
        "      <td>-0.018339</td>\n",
        "      <td>-0.209368</td>\n",
        "      <td>-0.148290</td>\n",
        "      <td>-0.170361</td>\n",
        "      <td>-1.661805</td>\n",
        "      <td>0.787737</td>\n",
        "      <td>0.112989</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td>0.058233</td>\n",
        "      <td>-0.049203</td>\n",
        "      <td>0.020969</td>\n",
        "      <td>0.205918</td>\n",
        "      <td>-0.135721</td>\n",
        "      <td>0.315265</td>\n",
        "      <td>0.468151</td>\n",
        "      <td>-0.750018</td>\n",
        "      <td>0.771557</td>\n",
        "      <td>-0.382222</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td>0.012410</td>\n",
        "      <td>-0.141158</td>\n",
        "      <td>0.545400</td>\n",
        "      <td>-0.272003</td>\n",
        "      <td>0.080392</td>\n",
        "      <td>0.150682</td>\n",
        "      <td>0.520734</td>\n",
        "      <td>0.237417</td>\n",
        "      <td>0.478175</td>\n",
        "      <td>-0.542300</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td>-0.054370</td>\n",
        "      <td>-0.176986</td>\n",
        "      <td>0.791650</td>\n",
        "      <td>-0.507854</td>\n",
        "      <td>0.237632</td>\n",
        "      <td>0.127386</td>\n",
        "      <td>0.047689</td>\n",
        "      <td>0.608506</td>\n",
        "      <td>-0.310632</td>\n",
        "      <td>0.006953</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20</th>\n",
        "      <td>-0.119417</td>\n",
        "      <td>-0.187457</td>\n",
        "      <td>0.859515</td>\n",
        "      <td>-0.044390</td>\n",
        "      <td>-0.334000</td>\n",
        "      <td>0.894803</td>\n",
        "      <td>-0.023480</td>\n",
        "      <td>1.142635</td>\n",
        "      <td>-0.565745</td>\n",
        "      <td>-0.248347</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21</th>\n",
        "      <td>-0.179259</td>\n",
        "      <td>0.108179</td>\n",
        "      <td>-0.084658</td>\n",
        "      <td>0.152295</td>\n",
        "      <td>-0.142386</td>\n",
        "      <td>0.689892</td>\n",
        "      <td>1.271638</td>\n",
        "      <td>0.044474</td>\n",
        "      <td>-1.349961</td>\n",
        "      <td>-0.357758</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22</th>\n",
        "      <td>0.100627</td>\n",
        "      <td>-0.015739</td>\n",
        "      <td>-0.090282</td>\n",
        "      <td>0.096584</td>\n",
        "      <td>0.009258</td>\n",
        "      <td>0.527267</td>\n",
        "      <td>-0.565116</td>\n",
        "      <td>1.111707</td>\n",
        "      <td>0.163581</td>\n",
        "      <td>0.815255</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23</th>\n",
        "      <td>-0.376431</td>\n",
        "      <td>0.281078</td>\n",
        "      <td>-0.026176</td>\n",
        "      <td>0.100573</td>\n",
        "      <td>0.031459</td>\n",
        "      <td>1.069647</td>\n",
        "      <td>-0.124224</td>\n",
        "      <td>0.651403</td>\n",
        "      <td>-0.092360</td>\n",
        "      <td>0.316426</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24</th>\n",
        "      <td>-0.380899</td>\n",
        "      <td>0.268742</td>\n",
        "      <td>-0.165695</td>\n",
        "      <td>0.073570</td>\n",
        "      <td>-0.045699</td>\n",
        "      <td>0.848666</td>\n",
        "      <td>-0.460987</td>\n",
        "      <td>1.551458</td>\n",
        "      <td>0.573746</td>\n",
        "      <td>0.096193</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25</th>\n",
        "      <td>0.106743</td>\n",
        "      <td>-0.094352</td>\n",
        "      <td>0.196349</td>\n",
        "      <td>-0.011513</td>\n",
        "      <td>0.328820</td>\n",
        "      <td>-0.103879</td>\n",
        "      <td>0.177128</td>\n",
        "      <td>1.017708</td>\n",
        "      <td>0.281874</td>\n",
        "      <td>-0.405540</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26</th>\n",
        "      <td>-0.140575</td>\n",
        "      <td>0.204710</td>\n",
        "      <td>-0.274524</td>\n",
        "      <td>0.035193</td>\n",
        "      <td>-0.082236</td>\n",
        "      <td>0.415470</td>\n",
        "      <td>-0.374055</td>\n",
        "      <td>-0.275993</td>\n",
        "      <td>1.461361</td>\n",
        "      <td>-0.126334</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27</th>\n",
        "      <td>-0.055457</td>\n",
        "      <td>0.080442</td>\n",
        "      <td>-0.283082</td>\n",
        "      <td>0.367196</td>\n",
        "      <td>-0.332354</td>\n",
        "      <td>0.784667</td>\n",
        "      <td>-0.409778</td>\n",
        "      <td>-1.676541</td>\n",
        "      <td>0.401624</td>\n",
        "      <td>0.679790</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28</th>\n",
        "      <td>-0.005913</td>\n",
        "      <td>-0.026093</td>\n",
        "      <td>0.086040</td>\n",
        "      <td>0.035231</td>\n",
        "      <td>0.027573</td>\n",
        "      <td>0.371463</td>\n",
        "      <td>-0.216851</td>\n",
        "      <td>1.133180</td>\n",
        "      <td>-0.176872</td>\n",
        "      <td>0.486857</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29</th>\n",
        "      <td>0.591925</td>\n",
        "      <td>-0.337183</td>\n",
        "      <td>-0.139755</td>\n",
        "      <td>0.450501</td>\n",
        "      <td>-0.332016</td>\n",
        "      <td>-0.478266</td>\n",
        "      <td>-0.163865</td>\n",
        "      <td>0.480327</td>\n",
        "      <td>-0.189202</td>\n",
        "      <td>0.252267</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>144</th>\n",
        "      <td>-0.078074</td>\n",
        "      <td>-0.019317</td>\n",
        "      <td>-0.056620</td>\n",
        "      <td>0.149414</td>\n",
        "      <td>-0.101171</td>\n",
        "      <td>0.220955</td>\n",
        "      <td>-0.054205</td>\n",
        "      <td>-0.357397</td>\n",
        "      <td>-0.059191</td>\n",
        "      <td>-0.206818</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>145</th>\n",
        "      <td>-0.149289</td>\n",
        "      <td>0.039942</td>\n",
        "      <td>-0.008424</td>\n",
        "      <td>-0.101733</td>\n",
        "      <td>0.200392</td>\n",
        "      <td>-0.633189</td>\n",
        "      <td>-0.125880</td>\n",
        "      <td>-0.140711</td>\n",
        "      <td>-0.235486</td>\n",
        "      <td>-0.239881</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>146</th>\n",
        "      <td>0.047361</td>\n",
        "      <td>0.086451</td>\n",
        "      <td>-0.370067</td>\n",
        "      <td>-0.108600</td>\n",
        "      <td>0.334677</td>\n",
        "      <td>-0.955675</td>\n",
        "      <td>0.340688</td>\n",
        "      <td>-0.653180</td>\n",
        "      <td>0.826731</td>\n",
        "      <td>0.107637</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>147</th>\n",
        "      <td>0.237340</td>\n",
        "      <td>-0.489763</td>\n",
        "      <td>0.492567</td>\n",
        "      <td>-0.397932</td>\n",
        "      <td>0.064934</td>\n",
        "      <td>-0.612413</td>\n",
        "      <td>-0.360581</td>\n",
        "      <td>-0.097809</td>\n",
        "      <td>0.260682</td>\n",
        "      <td>0.358774</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>148</th>\n",
        "      <td>-0.043225</td>\n",
        "      <td>0.044442</td>\n",
        "      <td>-0.145622</td>\n",
        "      <td>0.059692</td>\n",
        "      <td>0.006132</td>\n",
        "      <td>0.128980</td>\n",
        "      <td>-0.388342</td>\n",
        "      <td>-2.015151</td>\n",
        "      <td>0.748591</td>\n",
        "      <td>0.908627</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149</th>\n",
        "      <td>0.058094</td>\n",
        "      <td>0.041301</td>\n",
        "      <td>-0.231807</td>\n",
        "      <td>-0.187535</td>\n",
        "      <td>0.377445</td>\n",
        "      <td>-0.616993</td>\n",
        "      <td>0.391947</td>\n",
        "      <td>3.156149</td>\n",
        "      <td>-1.820047</td>\n",
        "      <td>-0.136670</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>150</th>\n",
        "      <td>-0.133486</td>\n",
        "      <td>0.129905</td>\n",
        "      <td>-0.246459</td>\n",
        "      <td>-0.054374</td>\n",
        "      <td>0.209681</td>\n",
        "      <td>-0.327699</td>\n",
        "      <td>0.940399</td>\n",
        "      <td>1.132260</td>\n",
        "      <td>-0.617160</td>\n",
        "      <td>-0.742009</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>151</th>\n",
        "      <td>-0.072359</td>\n",
        "      <td>-0.030587</td>\n",
        "      <td>0.238501</td>\n",
        "      <td>0.154416</td>\n",
        "      <td>-0.126653</td>\n",
        "      <td>1.157310</td>\n",
        "      <td>0.676173</td>\n",
        "      <td>0.628960</td>\n",
        "      <td>-0.439145</td>\n",
        "      <td>-0.112333</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>152</th>\n",
        "      <td>-0.068586</td>\n",
        "      <td>0.054903</td>\n",
        "      <td>-0.133743</td>\n",
        "      <td>0.054600</td>\n",
        "      <td>0.053248</td>\n",
        "      <td>-0.143986</td>\n",
        "      <td>0.683702</td>\n",
        "      <td>0.091838</td>\n",
        "      <td>0.110620</td>\n",
        "      <td>-0.426858</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>153</th>\n",
        "      <td>-0.203391</td>\n",
        "      <td>0.050251</td>\n",
        "      <td>0.051861</td>\n",
        "      <td>-0.006846</td>\n",
        "      <td>-0.013801</td>\n",
        "      <td>-0.391467</td>\n",
        "      <td>-0.148726</td>\n",
        "      <td>-0.133432</td>\n",
        "      <td>-0.116532</td>\n",
        "      <td>-0.156647</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>154</th>\n",
        "      <td>-0.020115</td>\n",
        "      <td>0.319331</td>\n",
        "      <td>-0.680575</td>\n",
        "      <td>-0.157049</td>\n",
        "      <td>-0.070399</td>\n",
        "      <td>-0.141374</td>\n",
        "      <td>-0.495247</td>\n",
        "      <td>-0.245707</td>\n",
        "      <td>-1.076936</td>\n",
        "      <td>1.165567</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>155</th>\n",
        "      <td>0.272655</td>\n",
        "      <td>0.036638</td>\n",
        "      <td>-0.397843</td>\n",
        "      <td>0.108506</td>\n",
        "      <td>-0.223899</td>\n",
        "      <td>0.079773</td>\n",
        "      <td>-0.200344</td>\n",
        "      <td>-0.355102</td>\n",
        "      <td>-0.801905</td>\n",
        "      <td>0.711372</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>156</th>\n",
        "      <td>-0.110824</td>\n",
        "      <td>0.165731</td>\n",
        "      <td>-0.527489</td>\n",
        "      <td>-0.114133</td>\n",
        "      <td>-0.132043</td>\n",
        "      <td>-0.709929</td>\n",
        "      <td>0.220098</td>\n",
        "      <td>0.167974</td>\n",
        "      <td>-0.371449</td>\n",
        "      <td>-0.604032</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>157</th>\n",
        "      <td>0.201305</td>\n",
        "      <td>0.035988</td>\n",
        "      <td>-0.408268</td>\n",
        "      <td>0.015855</td>\n",
        "      <td>-0.090204</td>\n",
        "      <td>0.001514</td>\n",
        "      <td>-0.144553</td>\n",
        "      <td>-0.137870</td>\n",
        "      <td>0.343765</td>\n",
        "      <td>0.097110</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>158</th>\n",
        "      <td>0.106333</td>\n",
        "      <td>0.026739</td>\n",
        "      <td>-0.246119</td>\n",
        "      <td>0.027167</td>\n",
        "      <td>0.050810</td>\n",
        "      <td>-0.122381</td>\n",
        "      <td>-0.199459</td>\n",
        "      <td>0.315506</td>\n",
        "      <td>1.320221</td>\n",
        "      <td>-0.892667</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>159</th>\n",
        "      <td>-0.124284</td>\n",
        "      <td>0.101632</td>\n",
        "      <td>0.122423</td>\n",
        "      <td>-0.141707</td>\n",
        "      <td>0.270858</td>\n",
        "      <td>0.082537</td>\n",
        "      <td>-0.357692</td>\n",
        "      <td>0.388423</td>\n",
        "      <td>0.112568</td>\n",
        "      <td>-0.071814</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>160</th>\n",
        "      <td>-0.223061</td>\n",
        "      <td>0.017432</td>\n",
        "      <td>0.189379</td>\n",
        "      <td>-0.033030</td>\n",
        "      <td>0.183141</td>\n",
        "      <td>-0.367873</td>\n",
        "      <td>0.061876</td>\n",
        "      <td>1.577056</td>\n",
        "      <td>1.269177</td>\n",
        "      <td>-1.789016</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>161</th>\n",
        "      <td>-0.126158</td>\n",
        "      <td>-0.002395</td>\n",
        "      <td>0.105174</td>\n",
        "      <td>0.108497</td>\n",
        "      <td>0.023111</td>\n",
        "      <td>0.121456</td>\n",
        "      <td>0.525046</td>\n",
        "      <td>0.813755</td>\n",
        "      <td>-0.419997</td>\n",
        "      <td>-1.237424</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>162</th>\n",
        "      <td>-0.087418</td>\n",
        "      <td>0.229426</td>\n",
        "      <td>-0.558770</td>\n",
        "      <td>-0.087872</td>\n",
        "      <td>-0.062017</td>\n",
        "      <td>-0.156628</td>\n",
        "      <td>-0.444060</td>\n",
        "      <td>-0.234126</td>\n",
        "      <td>-0.349554</td>\n",
        "      <td>0.576985</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>163</th>\n",
        "      <td>-0.513331</td>\n",
        "      <td>1.093384</td>\n",
        "      <td>-2.159653</td>\n",
        "      <td>-0.329175</td>\n",
        "      <td>0.452675</td>\n",
        "      <td>0.130665</td>\n",
        "      <td>-0.383294</td>\n",
        "      <td>0.553257</td>\n",
        "      <td>0.510484</td>\n",
        "      <td>0.149481</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>164</th>\n",
        "      <td>-0.188200</td>\n",
        "      <td>0.169674</td>\n",
        "      <td>-0.224519</td>\n",
        "      <td>0.000741</td>\n",
        "      <td>-0.120706</td>\n",
        "      <td>0.361259</td>\n",
        "      <td>-0.198537</td>\n",
        "      <td>-0.050458</td>\n",
        "      <td>-0.210795</td>\n",
        "      <td>0.054725</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>165</th>\n",
        "      <td>0.456393</td>\n",
        "      <td>-0.168390</td>\n",
        "      <td>-0.066864</td>\n",
        "      <td>0.237066</td>\n",
        "      <td>-0.217133</td>\n",
        "      <td>0.126381</td>\n",
        "      <td>1.023106</td>\n",
        "      <td>0.859609</td>\n",
        "      <td>-0.460133</td>\n",
        "      <td>-0.990954</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>166</th>\n",
        "      <td>0.367901</td>\n",
        "      <td>-0.178809</td>\n",
        "      <td>0.230556</td>\n",
        "      <td>-0.439234</td>\n",
        "      <td>0.475640</td>\n",
        "      <td>-0.014491</td>\n",
        "      <td>0.885820</td>\n",
        "      <td>1.036600</td>\n",
        "      <td>-0.450291</td>\n",
        "      <td>-0.579486</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>167</th>\n",
        "      <td>0.333590</td>\n",
        "      <td>-0.316804</td>\n",
        "      <td>0.541319</td>\n",
        "      <td>0.407108</td>\n",
        "      <td>-0.633090</td>\n",
        "      <td>1.417965</td>\n",
        "      <td>-0.223387</td>\n",
        "      <td>0.075747</td>\n",
        "      <td>0.780383</td>\n",
        "      <td>-0.253725</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>168</th>\n",
        "      <td>0.645561</td>\n",
        "      <td>-0.190207</td>\n",
        "      <td>-0.194061</td>\n",
        "      <td>0.315731</td>\n",
        "      <td>-0.118917</td>\n",
        "      <td>0.479675</td>\n",
        "      <td>-0.271538</td>\n",
        "      <td>-0.318921</td>\n",
        "      <td>1.698158</td>\n",
        "      <td>-0.194613</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>169</th>\n",
        "      <td>-0.190539</td>\n",
        "      <td>0.031307</td>\n",
        "      <td>0.128718</td>\n",
        "      <td>-0.044609</td>\n",
        "      <td>-0.415504</td>\n",
        "      <td>0.103558</td>\n",
        "      <td>-0.020902</td>\n",
        "      <td>-0.287875</td>\n",
        "      <td>-0.218479</td>\n",
        "      <td>-0.286611</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>170</th>\n",
        "      <td>0.047915</td>\n",
        "      <td>0.056805</td>\n",
        "      <td>-0.411004</td>\n",
        "      <td>0.173013</td>\n",
        "      <td>-0.516708</td>\n",
        "      <td>0.934653</td>\n",
        "      <td>0.581124</td>\n",
        "      <td>-0.130690</td>\n",
        "      <td>-0.267325</td>\n",
        "      <td>-0.441030</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>171</th>\n",
        "      <td>0.337927</td>\n",
        "      <td>-0.419069</td>\n",
        "      <td>0.820566</td>\n",
        "      <td>-0.302889</td>\n",
        "      <td>-0.008544</td>\n",
        "      <td>-0.405904</td>\n",
        "      <td>0.123648</td>\n",
        "      <td>0.149870</td>\n",
        "      <td>-0.856599</td>\n",
        "      <td>0.030303</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>172</th>\n",
        "      <td>-0.135038</td>\n",
        "      <td>-0.059998</td>\n",
        "      <td>0.556945</td>\n",
        "      <td>-0.248124</td>\n",
        "      <td>-0.103489</td>\n",
        "      <td>0.461193</td>\n",
        "      <td>-0.015642</td>\n",
        "      <td>1.129624</td>\n",
        "      <td>-0.541142</td>\n",
        "      <td>-0.111534</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>173</th>\n",
        "      <td>-0.919436</td>\n",
        "      <td>0.592867</td>\n",
        "      <td>0.273702</td>\n",
        "      <td>-2.022599</td>\n",
        "      <td>2.292047</td>\n",
        "      <td>0.105879</td>\n",
        "      <td>-0.075852</td>\n",
        "      <td>-0.820604</td>\n",
        "      <td>0.023941</td>\n",
        "      <td>0.226358</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>174 rows \u00d7 10 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 63,
       "text": [
        "     FrontTongueX  MidTongueX  BackTongueX  FrontTongueY  MidTongueY  \\\n",
        "0       -0.016784    0.113194    -0.045649     -0.131102    0.051586   \n",
        "1        0.385174   -0.188575     0.052170     -0.350112    0.311132   \n",
        "2        0.058937    0.058705    -0.170865     -0.183885    0.009933   \n",
        "3       -0.347491    0.346719    -0.405352     -0.185396   -0.154935   \n",
        "4        0.077035   -0.055551     0.022085      0.167029   -0.156917   \n",
        "5        0.022378    0.092889    -0.306242      0.084112   -0.081311   \n",
        "6        0.023430   -0.050927     0.080615      0.121351   -0.102925   \n",
        "7       -0.068856    0.026652     0.004040      0.149435   -0.178467   \n",
        "8        0.011662    0.080171    -0.169174     -0.426397    0.025873   \n",
        "9       -0.152007    0.035285     0.243506      0.179251   -0.426397   \n",
        "10       0.039370   -0.020255     0.038111     -0.209975    0.081847   \n",
        "11      -0.201339    0.156803    -0.147352     -0.173866   -0.089751   \n",
        "12       0.066960    0.161490    -0.455558     -0.110680   -0.052426   \n",
        "13      -0.000439   -0.074349     0.306744      0.023557   -0.177582   \n",
        "14      -0.061850   -0.020844     0.282932     -0.303326    0.182130   \n",
        "15      -0.162194    0.158350    -0.163957     -0.041736   -0.113606   \n",
        "16       0.042390   -0.094684     0.187372     -0.018339   -0.209368   \n",
        "17       0.058233   -0.049203     0.020969      0.205918   -0.135721   \n",
        "18       0.012410   -0.141158     0.545400     -0.272003    0.080392   \n",
        "19      -0.054370   -0.176986     0.791650     -0.507854    0.237632   \n",
        "20      -0.119417   -0.187457     0.859515     -0.044390   -0.334000   \n",
        "21      -0.179259    0.108179    -0.084658      0.152295   -0.142386   \n",
        "22       0.100627   -0.015739    -0.090282      0.096584    0.009258   \n",
        "23      -0.376431    0.281078    -0.026176      0.100573    0.031459   \n",
        "24      -0.380899    0.268742    -0.165695      0.073570   -0.045699   \n",
        "25       0.106743   -0.094352     0.196349     -0.011513    0.328820   \n",
        "26      -0.140575    0.204710    -0.274524      0.035193   -0.082236   \n",
        "27      -0.055457    0.080442    -0.283082      0.367196   -0.332354   \n",
        "28      -0.005913   -0.026093     0.086040      0.035231    0.027573   \n",
        "29       0.591925   -0.337183    -0.139755      0.450501   -0.332016   \n",
        "..            ...         ...          ...           ...         ...   \n",
        "144     -0.078074   -0.019317    -0.056620      0.149414   -0.101171   \n",
        "145     -0.149289    0.039942    -0.008424     -0.101733    0.200392   \n",
        "146      0.047361    0.086451    -0.370067     -0.108600    0.334677   \n",
        "147      0.237340   -0.489763     0.492567     -0.397932    0.064934   \n",
        "148     -0.043225    0.044442    -0.145622      0.059692    0.006132   \n",
        "149      0.058094    0.041301    -0.231807     -0.187535    0.377445   \n",
        "150     -0.133486    0.129905    -0.246459     -0.054374    0.209681   \n",
        "151     -0.072359   -0.030587     0.238501      0.154416   -0.126653   \n",
        "152     -0.068586    0.054903    -0.133743      0.054600    0.053248   \n",
        "153     -0.203391    0.050251     0.051861     -0.006846   -0.013801   \n",
        "154     -0.020115    0.319331    -0.680575     -0.157049   -0.070399   \n",
        "155      0.272655    0.036638    -0.397843      0.108506   -0.223899   \n",
        "156     -0.110824    0.165731    -0.527489     -0.114133   -0.132043   \n",
        "157      0.201305    0.035988    -0.408268      0.015855   -0.090204   \n",
        "158      0.106333    0.026739    -0.246119      0.027167    0.050810   \n",
        "159     -0.124284    0.101632     0.122423     -0.141707    0.270858   \n",
        "160     -0.223061    0.017432     0.189379     -0.033030    0.183141   \n",
        "161     -0.126158   -0.002395     0.105174      0.108497    0.023111   \n",
        "162     -0.087418    0.229426    -0.558770     -0.087872   -0.062017   \n",
        "163     -0.513331    1.093384    -2.159653     -0.329175    0.452675   \n",
        "164     -0.188200    0.169674    -0.224519      0.000741   -0.120706   \n",
        "165      0.456393   -0.168390    -0.066864      0.237066   -0.217133   \n",
        "166      0.367901   -0.178809     0.230556     -0.439234    0.475640   \n",
        "167      0.333590   -0.316804     0.541319      0.407108   -0.633090   \n",
        "168      0.645561   -0.190207    -0.194061      0.315731   -0.118917   \n",
        "169     -0.190539    0.031307     0.128718     -0.044609   -0.415504   \n",
        "170      0.047915    0.056805    -0.411004      0.173013   -0.516708   \n",
        "171      0.337927   -0.419069     0.820566     -0.302889   -0.008544   \n",
        "172     -0.135038   -0.059998     0.556945     -0.248124   -0.103489   \n",
        "173     -0.919436    0.592867     0.273702     -2.022599    2.292047   \n",
        "\n",
        "     BackTongueY  LipOpening  LipWidth      JawX      JawY  \n",
        "0       0.144505   -0.411826 -0.615102 -0.370511  0.890536  \n",
        "1      -0.838375   -0.264705 -0.868285 -0.156445  0.738678  \n",
        "2      -0.472895   -0.107436 -0.164013  0.093702  0.279770  \n",
        "3       0.235288   -0.115504 -0.137162  0.179457  0.305118  \n",
        "4       0.316097    1.477717 -0.820016 -1.248787 -0.370890  \n",
        "5       0.227204    0.629907 -0.405928 -0.238213 -0.366594  \n",
        "6       0.133585    0.495302 -0.147596 -0.207296 -0.409146  \n",
        "7       0.805722   -0.092662 -0.735853  0.697806  0.007550  \n",
        "8      -0.621662    0.381227  0.804530 -0.504299  0.126464  \n",
        "9       1.271683    0.216889 -0.350256 -0.111978 -0.075231  \n",
        "10     -0.296705   -0.026040 -0.280818  0.416691  0.081428  \n",
        "11     -0.402035   -0.296207  0.174523 -0.494182  0.086640  \n",
        "12     -0.160828    1.701323 -0.168305 -1.699293 -0.421316  \n",
        "13      0.643209    0.513103  1.084878  0.363536 -1.002593  \n",
        "14     -0.414353   -0.146584 -0.297878  0.242532  0.106996  \n",
        "15      0.243233   -0.293383 -0.117034  0.237710 -0.017171  \n",
        "16     -0.148290   -0.170361 -1.661805  0.787737  0.112989  \n",
        "17      0.315265    0.468151 -0.750018  0.771557 -0.382222  \n",
        "18      0.150682    0.520734  0.237417  0.478175 -0.542300  \n",
        "19      0.127386    0.047689  0.608506 -0.310632  0.006953  \n",
        "20      0.894803   -0.023480  1.142635 -0.565745 -0.248347  \n",
        "21      0.689892    1.271638  0.044474 -1.349961 -0.357758  \n",
        "22      0.527267   -0.565116  1.111707  0.163581  0.815255  \n",
        "23      1.069647   -0.124224  0.651403 -0.092360  0.316426  \n",
        "24      0.848666   -0.460987  1.551458  0.573746  0.096193  \n",
        "25     -0.103879    0.177128  1.017708  0.281874 -0.405540  \n",
        "26      0.415470   -0.374055 -0.275993  1.461361 -0.126334  \n",
        "27      0.784667   -0.409778 -1.676541  0.401624  0.679790  \n",
        "28      0.371463   -0.216851  1.133180 -0.176872  0.486857  \n",
        "29     -0.478266   -0.163865  0.480327 -0.189202  0.252267  \n",
        "..           ...         ...       ...       ...       ...  \n",
        "144     0.220955   -0.054205 -0.357397 -0.059191 -0.206818  \n",
        "145    -0.633189   -0.125880 -0.140711 -0.235486 -0.239881  \n",
        "146    -0.955675    0.340688 -0.653180  0.826731  0.107637  \n",
        "147    -0.612413   -0.360581 -0.097809  0.260682  0.358774  \n",
        "148     0.128980   -0.388342 -2.015151  0.748591  0.908627  \n",
        "149    -0.616993    0.391947  3.156149 -1.820047 -0.136670  \n",
        "150    -0.327699    0.940399  1.132260 -0.617160 -0.742009  \n",
        "151     1.157310    0.676173  0.628960 -0.439145 -0.112333  \n",
        "152    -0.143986    0.683702  0.091838  0.110620 -0.426858  \n",
        "153    -0.391467   -0.148726 -0.133432 -0.116532 -0.156647  \n",
        "154    -0.141374   -0.495247 -0.245707 -1.076936  1.165567  \n",
        "155     0.079773   -0.200344 -0.355102 -0.801905  0.711372  \n",
        "156    -0.709929    0.220098  0.167974 -0.371449 -0.604032  \n",
        "157     0.001514   -0.144553 -0.137870  0.343765  0.097110  \n",
        "158    -0.122381   -0.199459  0.315506  1.320221 -0.892667  \n",
        "159     0.082537   -0.357692  0.388423  0.112568 -0.071814  \n",
        "160    -0.367873    0.061876  1.577056  1.269177 -1.789016  \n",
        "161     0.121456    0.525046  0.813755 -0.419997 -1.237424  \n",
        "162    -0.156628   -0.444060 -0.234126 -0.349554  0.576985  \n",
        "163     0.130665   -0.383294  0.553257  0.510484  0.149481  \n",
        "164     0.361259   -0.198537 -0.050458 -0.210795  0.054725  \n",
        "165     0.126381    1.023106  0.859609 -0.460133 -0.990954  \n",
        "166    -0.014491    0.885820  1.036600 -0.450291 -0.579486  \n",
        "167     1.417965   -0.223387  0.075747  0.780383 -0.253725  \n",
        "168     0.479675   -0.271538 -0.318921  1.698158 -0.194613  \n",
        "169     0.103558   -0.020902 -0.287875 -0.218479 -0.286611  \n",
        "170     0.934653    0.581124 -0.130690 -0.267325 -0.441030  \n",
        "171    -0.405904    0.123648  0.149870 -0.856599  0.030303  \n",
        "172     0.461193   -0.015642  1.129624 -0.541142 -0.111534  \n",
        "173     0.105879   -0.075852 -0.820604  0.023941  0.226358  \n",
        "\n",
        "[174 rows x 10 columns]"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "feats[0]+\" ~ \"+ '+'.join(feats[ix])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 55,
       "text": [
        "'FrontTongueX ~ MidTongueX+BackTongueX+FrontTongueY+MidTongueY+BackTongueY+LipOpening+LipWidth+JawX+JawY'"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "feats[ix]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "array(['MidTongueX', 'BackTongueX', 'FrontTongueY', 'MidTongueY',\n",
        "       'BackTongueY', 'LipOpening', 'LipWidth', 'JawX', 'JawY'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ixgrid = np.ix_(mask)\n",
      "feats[ixgrid]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "array(['FrontTongueX', 'MidTongueX', 'MidTongueX', 'MidTongueX',\n",
        "       'MidTongueX', 'MidTongueX', 'MidTongueX', 'MidTongueX',\n",
        "       'MidTongueX', 'MidTongueX'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ixgrid"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "(array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1]),)"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "for feat in len(feats:\n",
      "    lr = sm.ols(formula = feat\" ~\"np.sum !feat,data=y).fit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "PatsyError",
       "evalue": "error tokenizing input (maybe an unclosed string?)\n    feat ~ !feat\n          ^",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mPatsyError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-17-0f863f31d592>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformula\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"feat ~ !feat\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/Users/david_conant/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36mfrom_formula\u001b[0;34m(cls, formula, data, subset, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         (endog, exog), missing_idx = handle_formula_data(data, None, formula,\n\u001b[1;32m    146\u001b[0m                                                          \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_env\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                                                          missing=missing)\n\u001b[0m\u001b[1;32m    148\u001b[0m         kwargs.update({'missing_idx': missing_idx,\n\u001b[1;32m    149\u001b[0m                        'missing': missing})\n",
        "\u001b[0;32m/Users/david_conant/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/statsmodels/formula/formulatools.py\u001b[0m in \u001b[0;36mhandle_formula_data\u001b[0;34m(Y, X, formula, depth, missing)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_using_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             result = dmatrices(formula, Y, depth, return_type='dataframe',\n\u001b[0;32m---> 65\u001b[0;31m                                NA_action=na_action)\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             result = dmatrices(formula, Y, depth, return_type='dataframe',\n",
        "\u001b[0;32m/Users/david_conant/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/patsy/highlevel.py\u001b[0m in \u001b[0;36mdmatrices\u001b[0;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0meval_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvalEnvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     (lhs, rhs) = _do_highlevel_design(formula_like, data, eval_env,\n\u001b[0;32m--> 297\u001b[0;31m                                       NA_action, return_type)\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mPatsyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model is missing required outcome variables\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/david_conant/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/patsy/highlevel.py\u001b[0m in \u001b[0;36m_do_highlevel_design\u001b[0;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     design_infos = _try_incr_builders(formula_like, data_iter_maker, eval_env,\n\u001b[0;32m--> 152\u001b[0;31m                                       NA_action)\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdesign_infos\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         return build_design_matrices(design_infos, data,\n",
        "\u001b[0;32m/Users/david_conant/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/patsy/highlevel.py\u001b[0m in \u001b[0;36m_try_incr_builders\u001b[0;34m(formula_like, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# fallthrough\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformula_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mformula_like\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelDesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_formula\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformula_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;31m# fallthrough\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformula_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelDesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/david_conant/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/patsy/desc.py\u001b[0m in \u001b[0;36mfrom_formula\u001b[0;34m(cls, tree_or_string)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_or_string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_formula\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_or_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_evalexpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/david_conant/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/patsy/parse_formula.py\u001b[0m in \u001b[0;36mparse_formula\u001b[0;34m(code, extra_operators)\u001b[0m\n\u001b[1;32m    146\u001b[0m     tree = infix_parse(_tokenize_formula(code, operator_strings),\n\u001b[1;32m    147\u001b[0m                        \u001b[0moperators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                        _atomic_token_types)\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParseNode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"~\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParseNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"~\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/david_conant/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/patsy/infix_parser.py\u001b[0m in \u001b[0;36minfix_parse\u001b[0;34m(tokens, operators, atomic_types, trace)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0mwant_noun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken_source\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reading next token (want_noun=%r)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwant_noun\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/david_conant/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/patsy/parse_formula.py\u001b[0m in \u001b[0;36m_tokenize_formula\u001b[0;34m(code, operator_strings)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPushbackAdapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mpytype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtoken_string\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmagic_token_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mToken\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_token_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_string\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/david_conant/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/patsy/util.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;31m# May raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_it\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0m__next__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/david_conant/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/patsy/tokens.py\u001b[0m in \u001b[0;36mpython_tokenize\u001b[0;34m(code)\u001b[0m\n\u001b[1;32m     37\u001b[0m                 raise PatsyError(\"error tokenizing input \"\n\u001b[1;32m     38\u001b[0m                                  \u001b[0;34m\"(maybe an unclosed string?)\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                                  origin)\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpytype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMMENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mPatsyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"comments are not allowed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mPatsyError\u001b[0m: error tokenizing input (maybe an unclosed string?)\n    feat ~ !feat\n          ^"
       ]
      }
     ],
     "prompt_number": 17
    }
   ],
   "metadata": {}
  }
 ]
}